{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import urllib.request\n",
    "import dateutil.parser\n",
    "import dateutil.rrule\n",
    "import dateutil.tz\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzUTC = dateutil.tz.gettz('UTC')\n",
    "tzLocal = dateutil.tz.gettz('Europe/London')\n",
    "\n",
    "earliestData = datetime.datetime.strptime('2020-04-20T00:00:00Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzUTC)\n",
    "dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time()).replace(tzinfo=tzUTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch any previous data\n",
    "previousDataEnd = None\n",
    "pointTsByIntervalOld = {}\n",
    "pdSourcesOld = None\n",
    "\n",
    "try:\n",
    "    pdSources = pd.read_pickle('../cache/recent-feature-counts-point-metadata.pkl')\n",
    "\n",
    "    for interval in pdSources['interval'].unique():\n",
    "        print('Loading data with %u second interval...' % interval)\n",
    "        pointTsByIntervalOld[interval] = pd.read_pickle('../cache/recent-feature-counts-pd-%usec.pkl' % interval)\n",
    "        intervalDataEnd = np.max(pointTsByIntervalOld[interval].index)\n",
    "\n",
    "        if previousDataEnd is None or intervalDataEnd > previousDataEnd:\n",
    "            previousDataEnd = intervalDataEnd\n",
    "            \n",
    "    print('Loaded previous data.')\n",
    "    pdSourcesOld = pdSources\n",
    "\n",
    "except:\n",
    "    pdSources = None\n",
    "    print('No existing data could be loaded.')\n",
    "    \n",
    "if previousDataEnd is None:\n",
    "    previousDataEnd = earliestData\n",
    "else:\n",
    "    previousDataEnd = datetime.datetime.combine(previousDataEnd.date(), datetime.datetime.min.time()).replace(tzinfo=tzUTC)\n",
    "\n",
    "for interval in pdSources['interval'].unique():\n",
    "    pointTsByIntervalOld[interval] = pointTsByIntervalOld[interval][pointTsByIntervalOld[interval].index < previousDataEnd]\n",
    "    \n",
    "print('  Start reading from %s' % previousDataEnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visionApiBase = 'https://uo-vision.dev.urbanobservatory.ac.uk/stills/dict'\n",
    "visionResponse = json.loads(\n",
    "    urllib.request.urlopen(visionApiBase).read().decode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdSources = pd.DataFrame.from_records(visionResponse).transpose()\n",
    "pdSources['min_date'] = pdSources['min_date'].apply(lambda d: datetime.datetime.strptime(d, '%Y-%m-%d').replace(tzinfo=tzUTC))\n",
    "pdSources['max_date'] = pdSources['max_date'].apply(lambda d: datetime.datetime.strptime(d, '%Y-%m-%d').replace(tzinfo=tzUTC))\n",
    "pdSources = pdSources.join(pdSourcesOld['interval'])\n",
    "\n",
    "camerasByInterval = {}\n",
    "pointTsByInterval = {}\n",
    "\n",
    "pdSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cameraId in pdSources.index:\n",
    "    #alreadyExists = False\n",
    "    #for testInterval in pointTsByInterval:\n",
    "    #    if pointTsByInterval[testInterval] is not None and (('%s: Source image' % cameraId) in pointTsByInterval[testInterval].columns):\n",
    "    #        alreadyExists = True\n",
    "            \n",
    "    #if alreadyExists:\n",
    "    #    continue\n",
    "    \n",
    "    source = pdSources[pdSources.index == cameraId].to_dict(orient='records')[0]\n",
    "    \n",
    "    print(cameraId)\n",
    "    print('  [', end='')\n",
    "    \n",
    "    sourceTs = None\n",
    "    \n",
    "    for date in dateutil.rrule.rrule(\n",
    "            dateutil.rrule.DAILY,\n",
    "            interval=1,\n",
    "            dtstart=source['min_date'] if source['min_date'] > previousDataEnd else previousDataEnd,\n",
    "            until=source['max_date']\n",
    "        ):\n",
    "        \n",
    "        windowResponse = None\n",
    "        windowAttempts = 0\n",
    "        while windowResponse is None:\n",
    "            try:\n",
    "                windowAttempts = windowAttempts + 1\n",
    "                windowResponse = json.loads(\n",
    "                    urllib.request.urlopen(\n",
    "                      'https://uo-vision.dev.urbanobservatory.ac.uk/stills/counts?location=%s&date=%s' % (cameraId, date.isoformat()[0:10])\n",
    "                    ).read().decode('utf-8')\n",
    "                )\n",
    "            except:\n",
    "                windowAttempts = windowAttempts + 1\n",
    "                print('x', end='')\n",
    "                time.sleep(min(windowAttempts, 10))\n",
    "\n",
    "        sourceOnDay = pd.DataFrame.from_records(pd.json_normalize(windowResponse), index=['ts'])\n",
    "        if not sourceOnDay.empty:\n",
    "            sourceOnDay.index = sourceOnDay.index.to_series().apply(lambda t: datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S').replace(tzinfo=tzUTC))\n",
    "        \n",
    "        if len(sourceOnDay.columns) == 0:\n",
    "            continue\n",
    "        \n",
    "        if sourceTs is None:\n",
    "            sourceTs = sourceOnDay\n",
    "        else:\n",
    "            sourceTs = sourceTs.append(sourceOnDay)\n",
    "        \n",
    "        print('.', end='')\n",
    "    \n",
    "    if sourceTs is None:\n",
    "        continue\n",
    "    \n",
    "    sourceTs.drop(columns=['camera'], inplace=True)\n",
    "    sourceTs.rename(inplace=True, errors='ignore', columns={\n",
    "        'url': 'Source image',\n",
    "        'counts.bus': 'Bus',\n",
    "        'counts.car': 'Car',\n",
    "        'counts.cyclist': 'Cyclist',\n",
    "        'counts.motorcyclist': 'Motorcyclist',\n",
    "        'counts.person': 'Person',\n",
    "        'counts.truck': 'Truck',\n",
    "        'counts.van': 'Van'\n",
    "    })\n",
    "    \n",
    "    sourceTs = sourceTs.loc[~sourceTs.index.duplicated(keep='first')]\n",
    "    tsInterval = sourceTs.index.to_series().diff().median().seconds\n",
    "    \n",
    "    if 'interval' in source:\n",
    "        sourceInterval = source['interval']\n",
    "    elif np.isnan(tsInterval) == True:\n",
    "        continue\n",
    "    else:\n",
    "        sourceInterval = min(600, round(tsInterval / 60) * 60)\n",
    "    camerasByInterval[cameraId] = sourceInterval\n",
    "\n",
    "    sourceTsNumeric = sourceTs.resample('%us' % sourceInterval).nearest().drop(columns=['Source image'], errors='ignore').fillna(0)\n",
    "    sourceTs = sourceTsNumeric.join(sourceTs['Source image'].resample('%us' % sourceInterval).nearest())\n",
    "    \n",
    "    sourceTs = sourceTs.add_prefix('%s: ' % cameraId)\n",
    "    \n",
    "    print('] Interval %u seconds' % sourceInterval)\n",
    "    \n",
    "    if sourceInterval not in pointTsByInterval:\n",
    "        pointTsByInterval[sourceInterval] = None\n",
    "    \n",
    "    if pointTsByInterval[sourceInterval] is None:\n",
    "        pointTsByInterval[sourceInterval] = sourceTs\n",
    "    else:\n",
    "        if ('%s: Source image' % cameraId) in pointTsByInterval[sourceInterval].columns:\n",
    "            pointTsByInterval[sourceInterval] = pointTsByInterval[sourceInterval].concat(sourceTs, sort=True, axis='index')\n",
    "        else:        \n",
    "            pointTsByInterval[sourceInterval] = pointTsByInterval[sourceInterval].join(sourceTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in pointTsByInterval:\n",
    "    if interval in pointTsByIntervalOld:\n",
    "        pointTsByInterval[interval] = pointTsByIntervalOld[interval].append(pointTsByInterval[interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointTsByInterval[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdSources.drop(columns=['interval'], inplace=True, errors='ignore')\n",
    "pdSourcesWithInterval = pdSources.join(pd.DataFrame.from_dict(camerasByInterval, orient='index', columns=['interval']))\n",
    "pdSourcesWithInterval.to_pickle('../cache/recent-feature-counts-point-metadata.pkl')\n",
    "pdSourcesWithInterval.to_csv('../output/recent-feature-counts-point-metadata.csv')\n",
    "pdSourcesWithInterval\n",
    "\n",
    "for interval in pointTsByInterval:\n",
    "    pointTsByInterval[interval].to_pickle('../cache/recent-feature-counts-pd-%usec.pkl' % interval)\n",
    "    pointTsByInterval[interval].to_csv('../output/recent-feature-counts-pd-%usec.csv' % interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for testing only...\n",
    "\n",
    "#pdSourcesAll = None\n",
    "\n",
    "#for interval in [60, 120, 300]:\n",
    "#    # Per hour...\n",
    "#    pdResampled = (pointTsByInterval[interval].resample('1800s').sum() * (1800 / interval) / 30)\n",
    "#    if pdSourcesAll is None:\n",
    "#        pdSourcesAll = pdResampled\n",
    "#    else:\n",
    "#        pdSourcesAll = pdSourcesAll.join(pdResampled)\n",
    "\n",
    "#pdSourcesAll.groupby(axis='columns', by=lambda x: x[x.find(':') + 1:]).sum().plot(figsize=(35, 15), stacked=False, legend=True)\n",
    "\n",
    "\n",
    "#pdSourcesAll[list(filter(lambda cn: 'Car' in cn, pdSourcesAll.columns))] #.plot(figsize=(35, 6.5), stacked=True, legend=False)\n",
    "        \n",
    "#ax = (dfPointTs[list(filter(lambda cn: 'Person' in cn, dfPointTs.columns))].resample('900s').mean() / 15).sum(axis=1).plot(figsize=(35, 6.5))\n",
    "#ax = (dfPointTs[list(filter(lambda cn: 'Person' in cn, dfPointTs.columns))].resample('900s').mean() / 15).plot(figsize=(35, 6.5), stacked=True, legend=False)\n",
    "#ax.set_ylabel('Pedestrians per minute')\n",
    "#ax = (dfPointTs[list(filter(lambda cn: 'Car' in cn, dfPointTs.columns))].resample('900s').mean() / 15).plot(figsize=(35, 6.5), stacked=True, legend=False)\n",
    "#ax.set_ylabel('Cars per minute')\n",
    "#ax = (dfPointTs[list(filter(lambda cn: 'Bus' in cn, dfPointTs.columns))].resample('3600s').mean()).plot(figsize=(35, 6.5), stacked=True, legend=False)\n",
    "#ax.set_ylabel('Buses per hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
