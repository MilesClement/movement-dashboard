{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import urllib.request\n",
    "import dateutil.parser\n",
    "import dateutil.rrule\n",
    "import dateutil.tz\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzUTC = dateutil.tz.gettz('UTC')\n",
    "tzLocal = dateutil.tz.gettz('Europe/London')\n",
    "\n",
    "earliestData = datetime.datetime.strptime('2020-01-01T00:00:00Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzUTC)\n",
    "dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time()).replace(tzinfo=tzUTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch any previous data\n",
    "# TODO: Switch this back to using a separate array for merging\n",
    "previousDataEnd = None\n",
    "pointTsByIntervalOld = {}\n",
    "pointTsByInterval = {}\n",
    "camerasByInterval = {}\n",
    "pdSourcesOld = None\n",
    "\n",
    "try:\n",
    "    pdSources = None\n",
    "    #pd.read_pickle('../cache/_IN_PROGRESS_recent-feature-counts-point-metadata.pkl')\n",
    "\n",
    "    for interval in [60, 120, 300, 600]:  # pdSources['interval'].unique():\n",
    "        print('Loading data with %u second interval...' % interval)\n",
    "        pointTsByIntervalOld[interval] = pd.read_pickle('../cache/recent-feature-counts-pd-%usec.pkl' % interval)\n",
    "        intervalDataEnd = np.max(pointTsByIntervalOld[interval].index)\n",
    "        \n",
    "        for cameraId in list(pointTsByIntervalOld[interval].columns.to_series().apply(lambda column: re.sub(':(.*)$', '', column)).unique()):\n",
    "            camerasByInterval[cameraId] = interval\n",
    "\n",
    "        if previousDataEnd is None or intervalDataEnd > previousDataEnd:\n",
    "            previousDataEnd = intervalDataEnd\n",
    "            \n",
    "    print('Loaded previous data.')\n",
    "    pdSourcesOld = pdSources\n",
    "\n",
    "except:\n",
    "    pdSources = None\n",
    "    print('No existing data could be loaded.')\n",
    "    \n",
    "if previousDataEnd is None:\n",
    "    previousDataEnd = earliestData\n",
    "else:\n",
    "    previousDataEnd = datetime.datetime.combine(previousDataEnd.date(), datetime.datetime.min.time()).replace(tzinfo=tzUTC)\n",
    "\n",
    "if pdSources is not None:\n",
    "    for interval in pdSources['interval'].unique():\n",
    "        pointTsByIntervalOld[interval] = pointTsByIntervalOld[interval][pointTsByIntervalOld[interval].index < previousDataEnd]\n",
    "    \n",
    "# Remove old data (for now...) to free up memory\n",
    "pointTsByIntervalOld = {}\n",
    "gc.collect()\n",
    "    \n",
    "print('  Start reading from %s' % previousDataEnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visionApiBase = 'https://uo-vision.dev.urbanobservatory.ac.uk/stills/dict'\n",
    "visionResponse = json.loads(\n",
    "    urllib.request.urlopen(visionApiBase).read().decode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdSources = pd.DataFrame.from_records(visionResponse).transpose()\n",
    "pdSources['min_date'] = pdSources['min_date'].apply(lambda d: datetime.datetime.strptime(d, '%Y-%m-%d').replace(tzinfo=tzUTC))\n",
    "pdSources['max_date'] = pdSources['max_date'].apply(lambda d: datetime.datetime.strptime(d, '%Y-%m-%d').replace(tzinfo=tzUTC))\n",
    "\n",
    "if len(camerasByInterval) > 0:\n",
    "    pdSources = pdSources.join(pd.DataFrame.from_dict(camerasByInterval, orient='index', columns=['interval']))\n",
    "\n",
    "camerasByInterval = {}\n",
    "#pointTsByInterval = {}\n",
    "camerasSinceSave = 0\n",
    "\n",
    "pdSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC = done, GH = done, SL, NT, ST, CM, NB, METCCTV, VAISALA\n",
    "#for cameraId in list(filter(lambda id: 'NC_' in id, list(pdSources.index))): # list(pdSources.index)[0:10]: # pdSources.index:\n",
    "for cameraId in pdSources.index:\n",
    "    alreadyExists = False\n",
    "    for testInterval in pointTsByInterval:\n",
    "        if pointTsByInterval[testInterval] is not None and (('%s: Source image' % cameraId) in pointTsByInterval[testInterval].columns):\n",
    "            alreadyExists = True\n",
    "            \n",
    "    if alreadyExists:\n",
    "        continue\n",
    "    \n",
    "    source = pdSources[pdSources.index == cameraId].to_dict(orient='records')[0]\n",
    "    \n",
    "    if cameraId == 'test_cam':\n",
    "        continue\n",
    "    \n",
    "    print(cameraId)\n",
    "    print('  [', end='')\n",
    "    \n",
    "    sourceTs = None\n",
    "\n",
    "    for date in dateutil.rrule.rrule(\n",
    "            dateutil.rrule.DAILY,\n",
    "            interval=1,\n",
    "            dtstart=source['min_date'] if source['min_date'] > previousDataEnd else previousDataEnd,\n",
    "            until=source['max_date']\n",
    "        ):\n",
    "        \n",
    "        windowResponse = None\n",
    "        windowAttempts = 0\n",
    "        while windowResponse is None:\n",
    "            try:\n",
    "                windowAttempts = windowAttempts + 1\n",
    "                windowResponse = json.loads(\n",
    "                    urllib.request.urlopen(\n",
    "                      'https://uo-vision.dev.urbanobservatory.ac.uk/stills/counts?location=%s&date=%s' % (cameraId, date.isoformat()[0:10])\n",
    "                    ).read().decode('utf-8')\n",
    "                )\n",
    "            except:\n",
    "                windowAttempts = windowAttempts + 1\n",
    "                print('x', end='')\n",
    "                time.sleep(min(windowAttempts, 10))\n",
    "\n",
    "        for i, r in enumerate(windowResponse):\n",
    "            for count in windowResponse[i]['counts']:\n",
    "                if not isinstance(windowResponse[i]['counts'][count], int):\n",
    "                    windowResponse[i]['counts'][count] = windowResponse[i]['counts'][count]['count']\n",
    "                \n",
    "        sourceOnDay = pd.DataFrame.from_records(pd.json_normalize(windowResponse), index=['ts'])\n",
    "        if not sourceOnDay.empty:\n",
    "            sourceOnDay.index = sourceOnDay.index.to_series().apply(lambda t: datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S').replace(tzinfo=tzUTC))\n",
    "        \n",
    "        if len(sourceOnDay.columns) == 0:\n",
    "            print('-', end='')\n",
    "            continue\n",
    "        \n",
    "        if sourceTs is None:\n",
    "            sourceTs = sourceOnDay\n",
    "        else:\n",
    "            sourceTs = sourceTs.append(sourceOnDay)\n",
    "        \n",
    "        print('#', end='')\n",
    "    \n",
    "    if sourceTs is None:\n",
    "        print('] No data')\n",
    "        continue\n",
    "    \n",
    "    sourceTs.drop(columns=['camera'], inplace=True)\n",
    "    sourceTs.rename(inplace=True, errors='ignore', columns={\n",
    "        'url': 'Source image',\n",
    "        'counts.bus': 'Bus',\n",
    "        'counts.car': 'Car',\n",
    "        'counts.cyclist': 'Cyclist',\n",
    "        'counts.motorcyclist': 'Motorcyclist',\n",
    "        'counts.person': 'Person',\n",
    "        'counts.truck': 'Truck',\n",
    "        'counts.van': 'Van'\n",
    "    })\n",
    "    \n",
    "    sourceTs = sourceTs.loc[~sourceTs.index.duplicated(keep='first')]\n",
    "    tsInterval = min(600.0, sourceTs.index.to_series().diff().dropna().apply(lambda x: max(60.0, round(x.seconds / 30) * 30)).quantile(0.01))\n",
    "    \n",
    "    # No strange four or nine minute intervals please...\n",
    "    if tsInterval > 120 and tsInterval < 300:\n",
    "        tsInterval = 120\n",
    "    elif tsInterval > 300 and tsInterval < 600:\n",
    "        tsInterval = 300\n",
    "    \n",
    "    if 'interval' in source and np.isnan(source['interval']) == False:\n",
    "        sourceInterval = source['interval']\n",
    "    elif np.isnan(tsInterval) == True:\n",
    "        continue\n",
    "    else:\n",
    "        sourceInterval = min(600, round(tsInterval / 60) * 60)\n",
    "    camerasByInterval[cameraId] = sourceInterval\n",
    "\n",
    "    sourceTsNumeric = sourceTs.resample('%us' % sourceInterval).nearest(limit=1).drop(columns=['Source image'], errors='ignore')\n",
    "    sourceTs = sourceTsNumeric.join(sourceTs['Source image'].resample('%us' % sourceInterval).nearest(limit=1))\n",
    "    \n",
    "    sourceTs = sourceTs.add_prefix('%s: ' % cameraId)\n",
    "    \n",
    "    print('] Interval %u seconds' % sourceInterval)\n",
    "    \n",
    "    if sourceInterval not in pointTsByInterval:\n",
    "        pointTsByInterval[sourceInterval] = None\n",
    "    \n",
    "    if sourceInterval not in pointTsByInterval or pointTsByInterval[sourceInterval] is None:\n",
    "        pointTsByInterval[sourceInterval] = sourceTs\n",
    "    else:\n",
    "        if ('%s: Source image' % cameraId) in pointTsByInterval[sourceInterval].columns:\n",
    "            pointTsByInterval[sourceInterval] = pointTsByInterval[sourceInterval].concat(sourceTs, sort=True, axis='index')\n",
    "        else:        \n",
    "            pointTsByInterval[sourceInterval] = pointTsByInterval[sourceInterval].join(sourceTs)\n",
    "            \n",
    "    # Periodic saves for sanity\n",
    "    camerasSinceSave = camerasSinceSave + 1\n",
    "    \n",
    "    if camerasSinceSave > 5 or len(sourceTs) > 20000:\n",
    "        pdSourcesWithoutInterval = pdSources.drop(columns=['interval'], errors='ignore')\n",
    "        pdSourcesWithInterval = pdSourcesWithoutInterval.join(pd.DataFrame.from_dict(camerasByInterval, orient='index', columns=['interval']))\n",
    "        pdSourcesWithInterval.to_pickle('../cache/_IN_PROGRESS_recent-feature-counts-point-metadata.pkl')\n",
    "\n",
    "        pointTsByInterval[sourceInterval].to_pickle('../cache/_IN_PROGRESS_recent-feature-counts-pd-%usec.pkl' % sourceInterval)\n",
    "        \n",
    "        camerasSinceSave = 0\n",
    "        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resume a failed process only...\n",
    "#for interval in [60, 120, 300, 600]:  # pdSources['interval'].unique():\n",
    "#    print('Loading data with %u second interval...' % interval)\n",
    "#    pointTsByInterval[interval] = pd.read_pickle('../cache/_IN_PROGRESS_recent-feature-counts-pd-%usec.pkl' % interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointTsFinalByInterval = {}\n",
    "\n",
    "for interval in pointTsByInterval:\n",
    "    oldData = pd.read_pickle('../cache/recent-feature-counts-pd-%usec.pkl' % interval)\n",
    "    pointTsFinalByInterval[interval] = oldData.append(pointTsByInterval[interval])\n",
    "    pointTsFinalByInterval[interval] = pointTsFinalByInterval[interval].loc[~pointTsFinalByInterval[interval].index.duplicated(keep='first')]\n",
    "    \n",
    "    oldData = None\n",
    "    pointTsByInterval[interval] = None\n",
    "    \n",
    "    gc.collect()\n",
    "    print('Writing output for interval %u...' % interval)\n",
    "    pointTsFinalByInterval[interval].to_pickle('../cache/recent-feature-counts-pd-%usec.pkl' % interval)\n",
    "    pointTsFinalByInterval[interval] = None\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointTsByInterval = None\n",
    "pointTsByIntervalOld = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pointTsFinalByInterval[60].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdSources.drop(columns=['interval'], inplace=True, errors='ignore')\n",
    "pdSourcesWithInterval = pdSources.join(pd.DataFrame.from_dict(camerasByInterval, orient='index', columns=['interval']))\n",
    "pdSourcesWithInterval.to_pickle('../cache/recent-feature-counts-point-metadata.pkl')\n",
    "pdSourcesWithInterval.to_csv('../output/recent-feature-counts-point-metadata.csv')\n",
    "pdSourcesWithInterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
