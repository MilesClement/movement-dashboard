{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import urllib.request\n",
    "import re\n",
    "import gc\n",
    "import io\n",
    "import dateutil.parser\n",
    "import dateutil.rrule\n",
    "import dateutil.tz\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used across most of the plots for people flows\n",
    "tzUTC = dateutil.tz.gettz('UTC')\n",
    "tzLocal = dateutil.tz.gettz('Europe/London')\n",
    "dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time()).replace(tzinfo=tzLocal)\n",
    "\n",
    "trafficCountInterval = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't do anything with old data yet, because of the large number of gaps in recent...\n",
    "try:\n",
    "    dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time()).replace(tzinfo=tzLocal)\n",
    "    dfPointInterpTsOld = pd.read_pickle('../cache/sheffield-recent-traffic-volumes-pd.pkl')\n",
    "    dfPointInterpTsOld = dfPointInterpTsOld[dfPointInterpTsOld.index < dateToday - pd.Timedelta(days=15)]\n",
    "    baselineEnd = np.max(dfPointInterpTsOld.index).replace(tzinfo=tzLocal).astimezone(tzUTC)\n",
    "    print('Loaded previous data.')\n",
    "    print('  %s' % baselineEnd)\n",
    "except:\n",
    "    dfPointInterpTsOld = None\n",
    "    baselineEnd = dateToday - pd.Timedelta(days=60)\n",
    "    print('No existing data could be loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficCountFetchFrom = (baselineEnd - pd.Timedelta(hours=84)).isoformat().replace('+00:00', '')\n",
    "trafficCountUrl = 'https://sheffield-portal.urbanflows.ac.uk/uflobin/ufdex?freqInMin=5&byContent=TRAFF_FLOW&bySelect=TRAFF_FLOW&aktion=CSV_show&Tfrom=%s' % trafficCountFetchFrom\n",
    "\n",
    "csvCountTs = urllib.request.urlopen(trafficCountUrl).read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdCountTs = pd.read_csv(io.StringIO(csvCountTs), comment='#', names=['Timestamp', 'Sensor', 'Flow'], header=0)\n",
    "# pdCountTs = pdCountTs.pivot(columns='Sensor', index='Timestamp', values='Flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPointTs = None\n",
    "\n",
    "for loopId in pdCountTs['Sensor'].unique():\n",
    "    print('Processing timeseries for counter \"%s\"...' % loopId)\n",
    "    \n",
    "    pdLoopTs = pdCountTs[pdCountTs['Sensor'] == loopId].copy()\n",
    "    pdLoopTs.drop(columns=['Sensor'], inplace=True)\n",
    "    pdLoopTs['Timestamp'] = pdLoopTs['Timestamp'].apply(lambda t: datetime.datetime.fromtimestamp(t).replace(tzinfo=tzUTC).astimezone(tzLocal))\n",
    "    pdLoopTs.set_index('Timestamp', inplace=True, drop=True)\n",
    "    \n",
    "    if (pdLoopTs['Flow'].sum() == 0.0):\n",
    "        print('  No vehicle flow data available.')\n",
    "        continue\n",
    "    \n",
    "    pdLoopTs.rename(columns={'Flow': loopId}, inplace=True)\n",
    "    \n",
    "    if dfPointTs is None:\n",
    "        dfPointTs = pdLoopTs\n",
    "    else:\n",
    "        dfPointTs = dfPointTs.join(\n",
    "            pdLoopTs, \n",
    "            how='outer'\n",
    "        )\n",
    "        pdLoopTs = None\n",
    "    \n",
    "dfPointTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incoming data is actually 5 minutes, so align to that\n",
    "# then accept we have lots of gaps and make it 15 minute data\n",
    "# and then interpolate to fill gaps if possible, maximum of an hour distance\n",
    "dfPointInterpTs = dfPointTs \\\n",
    "    .resample('900s').median() \\\n",
    "    .interpolate('linear', limit=2) \\\n",
    "    .apply(lambda v: v * 15)\n",
    "\n",
    "dfPointInterpTsMerged = dfPointInterpTsOld[dfPointInterpTsOld.index < baselineEnd - pd.Timedelta(hours=72)].append(dfPointInterpTs)\n",
    "dfPointInterpTsMerged = dfPointInterpTsMerged.loc[~dfPointInterpTsMerged.index.duplicated(keep='first')]\n",
    "dfPointInterpTsMerged.to_pickle('../cache/sheffield-recent-traffic-volumes-pd.pkl')\n",
    "\n",
    "# 15 minute timeseries\n",
    "#dfPointInterpTs.tail(50)\n",
    "\n",
    "# Disable for now... need to be appending this data\n",
    "#dfPointInterpTs.to_pickle('../cache/sheffield-recent-traffic-volumes-pd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
