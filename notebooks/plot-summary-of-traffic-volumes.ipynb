{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import urllib.request\n",
    "import dateutil.parser\n",
    "import dateutil.rrule\n",
    "import datetime\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**To be written.**\n",
    "\n",
    "For each day, the following percentages are given with respect to the average vehicles per hour:\n",
    " * Change since the day before\n",
    " * Change since the same weekday last week\n",
    " * Change compared to the median for the same weekday calculated over the last year\n",
    " \n",
    "Statistics are provided for the morning peak, afternoon peak, inter-peak period (essentially daytime outside of peak hours), and night. As vehicle traffic is unlikely to be evenly distributed across these periods, the statistics for the current period will be volatile while data is still coming in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used across most of the plots for people flows\n",
    "dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time())\n",
    "trafficCountInterval = 900\n",
    "pdTrafficCount = pickle.load(open('../cache/recent-traffic-volumes-pd.pkl', 'rb'))\n",
    "\n",
    "# TODO: Make this reflect the last entry in the frame, not the time now\n",
    "print('Last data obtained %s' \n",
    "    % (np.max(pdTrafficCount.index).strftime('%d %B %Y %H:%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExE5Ulih1KDJ"
   },
   "outputs": [],
   "source": [
    "# Ignore non-numeric columns in the dataframe\n",
    "plottableTypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "perMinuteFactor = (trafficCountInterval / 60)\n",
    "\n",
    "daysToInclude = 15\n",
    "daysToSkip = ['17/03/2020', '18/03/2020'] # Data collection wasn't fully in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryPoints = {\n",
    "    'Traffic volumes from A1 towards Newcastle upon Tyne': {\n",
    "        'J66 Angel (Northbound)': 'CAJT_GHA167_NB4_DR3.start',\n",
    "        'J69 Redheugh (Northbound)': 'CAJT_GHA184_DWR1_RB.start',\n",
    "        # 'J75 Denton (Eastbound)': 'CAJT_NCA186_WR4_WR3.start', # Denton data seems dodgy to me...\n",
    "        'J76 Blakelaw (Eastbound)': 'CAJT_NCB6324_SR2_SR1.start'\n",
    "    },\n",
    "    'Traffic volumes at A1 leaving Newcastle upon Tyne': {\n",
    "        'J66 Angel (Southbound)': 'CAJT_GHA167_DR3_NB4.end',\n",
    "        'J69 Redheugh (Soutbound)': 'CAJT_GHA184_RB_A1.end',\n",
    "        # 'J75 Denton (Westbound)': 'CAJT_NCA186_WR3_WR4.end',\n",
    "        'J76 Blakelaw (Westbound)': 'CAJT_NCB6324_SR1_SR2.end'\n",
    "    },\n",
    "    'Traffic volumes on Jesmond Road and Coast Road': {\n",
    "        'Central Motorway (Westbound)': 'CAJT_NCA1058_SR3_JR1.end',\n",
    "        'Central Motorway (Eastbound)': 'CAJT_NCA1058_JR1_SR3.start'\n",
    "    },\n",
    "    'Traffic volumes on Tyne Bridge': {\n",
    "        'Tyne Bridge (Northbound)': 'CAJT_GHA167_DR1_TB.end',\n",
    "        'Tyne Bridge (Southbound)': 'CAJT_GHA167_TB_DR1.start'\n",
    "        # No plate read data for these, unfortunately.\n",
    "        #'Redheugh Bridge (Northbound)': 'CAJT_GHA184_DWR1_RB.end',\n",
    "        #'Redheugh Bridge (Southbound)': 'CAJT_GHA184_RB_A1.start',\n",
    "        #'Scotswood Bridge (Eastbound)': 'CAJT_NCA695_SB_SWR3.start',\n",
    "        #'Scotswood Bridge (Westbound)': 'CAJT_NCA695_SWR3_SB.end'\n",
    "    },\n",
    "    'Traffic volumes on Great North Road': {\n",
    "        'Broadway (Southbound)': 'CAJT_NCB1318_GNR3_GNR2.start',\n",
    "        'Broadway (Northbound)': 'CAJT_NCB1318_GNR2_GNR3.end'\n",
    "    },\n",
    "    'Traffic volumes within Sunderland': {\n",
    "        'Stockton Rd (Southbound)': 'CAJT_SLA1231_GT1_RR1.start',\n",
    "        'Stockton Rd (Northbound)': 'CAJT_SLA1231_RR1_GT1.end'\n",
    "    }\n",
    "}\n",
    "\n",
    "def classifyTime(t):\n",
    "    hour = int(t.strftime('%H'))\n",
    "    if hour < 7:\n",
    "        return 'Night (19:00 - 07:00)'\n",
    "    elif hour < 10:\n",
    "        return 'Morning peak (07:00 - 10:00)'\n",
    "    elif hour < 16:\n",
    "        return 'Inter-peak (10:00 - 16:00)'\n",
    "    elif hour < 19:\n",
    "        return 'Evening peak (16:00 - 19:00)'\n",
    "    else:\n",
    "        return 'Night (19:00 - 07:00)'\n",
    "\n",
    "periodDurations = {\n",
    "    'Morning peak (07:00 - 10:00)': 3,   # 7 - 10\n",
    "    'Inter-peak (10:00 - 16:00)': 6,     # 10 - 16\n",
    "    'Evening peak (16:00 - 19:00)': 3,   # 16 - 19\n",
    "    'Night (19:00 - 07:00)': 12\n",
    "}\n",
    "\n",
    "allPeriods = list(periodDurations.keys())\n",
    "\n",
    "for sensorName in summaryPoints.keys():\n",
    "    dateIndex = []\n",
    "    directionIndex = []\n",
    "    summaryData = []\n",
    "    \n",
    "    columnsRequired = summaryPoints[sensorName].values()\n",
    "    dfSensor = pdTrafficCount[columnsRequired].copy()\n",
    "    dfSensor.insert(0, 'Date', dfSensor.index.to_series().apply(lambda t: t.date()))\n",
    "    dfSensor.insert(0, 'Day of week', dfSensor.index.to_series().apply(lambda t: t.strftime('%A')))\n",
    "    dfSensor.insert(1, 'Time of day', dfSensor.index.to_series().apply(lambda t: t.strftime('%H:%M:%S')))\n",
    "    dfSensor.insert(1, 'Period', dfSensor.index.to_series().apply(classifyTime))\n",
    "\n",
    "    dfDailyPeriodTotals = dfSensor.groupby(['Date', 'Day of week', 'Period'], as_index=False).sum()\n",
    "    dfAveragePeriodTotals = dfDailyPeriodTotals.groupby(['Day of week', 'Period'], as_index=False).median()\n",
    "    \n",
    "    for d in range(daysToInclude, -1, -1):\n",
    "        sensorDate = dateToday - pd.Timedelta(days=d)\n",
    "        \n",
    "        if sensorDate.strftime('%d/%m/%Y') in daysToSkip:\n",
    "            continue\n",
    "        \n",
    "        dateIndex.extend(np.repeat(sensorDate.strftime('%A %d %B'), len(summaryPoints[sensorName].keys())))\n",
    "\n",
    "        directionColumns = dfSensor.select_dtypes(plottableTypes).columns\n",
    "        directionIndex.extend(summaryPoints[sensorName].keys())\n",
    "                         \n",
    "        dfSensorOnDate = dfSensor.loc \\\n",
    "            [(sensorDate <= dfSensor.index) &\n",
    "            (dfSensor.index < sensorDate + pd.Timedelta(hours=24))] \\\n",
    "            .copy() \\\n",
    "            .groupby(['Period']) \\\n",
    "            .agg(['sum', 'count']) \\\n",
    "            [directionColumns]\n",
    "        dfSensorLastWeek = dfSensor.loc \\\n",
    "            [(sensorDate - pd.Timedelta(days=7) <= dfSensor.index) &\n",
    "            (dfSensor.index < sensorDate - pd.Timedelta(days=7) + pd.Timedelta(hours=24))] \\\n",
    "            .copy() \\\n",
    "            .groupby(['Period']) \\\n",
    "            .agg(['sum', 'count']) \\\n",
    "            [directionColumns]\n",
    "        dfSensorYesterday = dfSensor.loc \\\n",
    "            [(sensorDate - pd.Timedelta(days=1) <= dfSensor.index) &\n",
    "            (dfSensor.index < sensorDate - pd.Timedelta(days=1) + pd.Timedelta(hours=24))] \\\n",
    "            .copy() \\\n",
    "            .groupby(['Period']) \\\n",
    "            .agg(['sum', 'count']) \\\n",
    "            [directionColumns]\n",
    "\n",
    "        dfSensorAverageDayOfWeek = dfAveragePeriodTotals[dfAveragePeriodTotals['Day of week'] == sensorDate.strftime('%A')]\n",
    "\n",
    "        for direction in summaryPoints[sensorName]:\n",
    "            directionColumn = summaryPoints[sensorName][direction]\n",
    "            summaryRow = []\n",
    "            for period in allPeriods:\n",
    "                periodStats = dfSensorOnDate[dfSensorOnDate.index == period][directionColumn]\n",
    "                if not periodStats['sum'].empty:\n",
    "\n",
    "                    # Convert to an hourly value\n",
    "                    periodTotal = periodStats['sum'].values[0]\n",
    "                    periodHourly = periodTotal / periodStats['count'].values[0] * (3600 / trafficCountInterval)\n",
    "\n",
    "                    # Change on yesterday\n",
    "                    yesterdayHourly = dfSensorYesterday[dfSensorYesterday.index == period][directionColumn]\n",
    "                    yesterdayHourly = (yesterdayHourly['sum'].values[0] / yesterdayHourly['count'].values[0]) * (3600 / trafficCountInterval)\n",
    "                    if (sensorDate - pd.Timedelta(days=1)).strftime('%d/%m/%Y') in daysToSkip:\n",
    "                        yesterdayChange = None\n",
    "                    else:\n",
    "                        yesterdayChange = (periodHourly - yesterdayHourly) / yesterdayHourly\n",
    "\n",
    "                    # Change on last week\n",
    "                    lastWeekHourly = dfSensorLastWeek[dfSensorLastWeek.index == period][directionColumn]\n",
    "                    lastWeekHourly = (lastWeekHourly['sum'].values[0] / lastWeekHourly['count'].values[0]) * (3600 / trafficCountInterval)\n",
    "                    lastWeekChange = (periodHourly - lastWeekHourly) / lastWeekHourly\n",
    "\n",
    "                    # Change on normal profile\n",
    "                    profileHourly = dfSensorAverageDayOfWeek[dfSensorAverageDayOfWeek['Period'] == period][directionColumn]\n",
    "                    profileHourly = profileHourly.values[0] / periodDurations[period]\n",
    "                    profileChange = (periodHourly - profileHourly) / profileHourly\n",
    "\n",
    "                    summaryRow.extend([\n",
    "                        periodHourly, # Total\n",
    "                        yesterdayChange, # Change on yesterday\n",
    "                        lastWeekChange, # Change on last week\n",
    "                        profileChange, # Change on average\n",
    "                    ])\n",
    "                else:\n",
    "                    summaryRow.extend(np.repeat(0.0, 4))     \n",
    "            summaryData.append(summaryRow)\n",
    "\n",
    "    rowIndex = pd.MultiIndex.from_arrays([\n",
    "            dateIndex,\n",
    "            directionIndex\n",
    "        ],\n",
    "        names=['Date', 'Direction']\n",
    "    )\n",
    "\n",
    "    formattersSummary = {}\n",
    "    colPeriods = []\n",
    "    colStats = []\n",
    "    for period in allPeriods:\n",
    "        formattersSummary[(period, 'Hourly average flow')] = '{:,.0f}'\n",
    "        formattersSummary[(period, 'Change from day before (%)')] = '{:+,.0%}'\n",
    "        formattersSummary[(period, 'Change from week before (%)')] = '{:+,.0%}'\n",
    "        formattersSummary[(period, 'Change from annual average (%)')] = '{:+,.0%}'\n",
    "        colPeriods.extend(np.repeat(period, 4))\n",
    "        colStats.extend([\n",
    "            'Hourly average flow',\n",
    "            'Change from day before (%)',\n",
    "            'Change from week before (%)',\n",
    "            'Change from annual average (%)'\n",
    "        ])\n",
    "\n",
    "    colIndex = pd.MultiIndex.from_arrays(\n",
    "        [colPeriods, colStats],\n",
    "        names=['Period', 'Statistic']\n",
    "    )\n",
    "\n",
    "    dfSummary = pd.DataFrame(summaryData, columns=colIndex, index=rowIndex)\n",
    "    dfSummaryStyler = dfSummary.style \\\n",
    "        .format(formattersSummary) \\\n",
    "        .set_caption(sensorName) \\\n",
    "        .set_table_styles(\n",
    "            [dict(selector=\"th\",props=[('text-align', 'center')]),\n",
    "                dict(selector=\"tr:nth-child(2) th.col_heading\",\n",
    "                     props=[('vertical-align', 'bottom'),\n",
    "                            ('writing-mode', 'vertical-rl'),\n",
    "                            ]),\n",
    "             dict(selector=\"caption\", props=[('font-weight', 'bold'), ('font-size', '120%')]),\n",
    "             dict(selector=\"tr th:nth-child(2)\", props=[('white-space', 'nowrap')])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    periodBarColours = {\n",
    "        'Morning peak (07:00 - 10:00)': '#FFA07A50',\n",
    "        'Inter-peak (10:00 - 16:00)': '#EE1F5F50',\n",
    "        'Evening peak (16:00 - 19:00)': '#FFA07A50',\n",
    "        'Night (19:00 - 07:00)': '#A0FF7A50'\n",
    "    }\n",
    "\n",
    "    for period in allPeriods:\n",
    "        dfSummaryStyler.background_gradient(\n",
    "            subset=[(period, 'Change from annual average (%)')],\n",
    "            vmin=-1.0,\n",
    "            vmax=1.0,\n",
    "            cmap='PiYG'\n",
    "        )\n",
    "        dfSummaryStyler.bar(subset=[(period, 'Hourly average flow')], color=periodBarColours[period], vmin=0)\n",
    "\n",
    "    display(HTML(dfSummaryStyler._repr_html_().replace('+nan%', 'N/A')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
